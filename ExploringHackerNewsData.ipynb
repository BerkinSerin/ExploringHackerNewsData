{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, we'll work with a data set of submissions to popular technology site [Hacker News.](https://news.ycombinator.com/)\n",
    "\n",
    "\n",
    "We're specifically interested in posts whose titles begin with either *Ask HN* or *Show HN*. Users submit Ask HN posts to ask the Hacker News community a specific question. Below are a couple examples:\n",
    "\n",
    "- Ask HN: How to improve my personal website?\n",
    "- Ask HN: Am I the only one outraged by Twitter shutting down share counts?\n",
    "- Ask HN: Aby recent changes to CSS that broke mobile?\n",
    "\n",
    "Likewise, users submit *Show HN* posts to show the Hacker News community a project, product, or just generally something interesting. Below are a couple of examples:\n",
    "\n",
    "- Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform'\n",
    "- Show HN: Something pointless I made\n",
    "- Show HN: Shanhu.io, a programming playground powered by e8vm\n",
    "\n",
    "We'll compare these two types of posts to determine the following:\n",
    "\n",
    "- Do *Ask HN* or *Show HN* receive more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "We will also analyze points on Ask HN and Show HN along with the main goal.\n",
    "\n",
    "*We are not going to use pandas or numpy in this project.*\n",
    "\n",
    "\n",
    "\n",
    "## Import CSV\n",
    "\n",
    "Let's start by importing the libraries we need and reading the data set into a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "\n",
    "opened_file = open('hacker_news.csv', encoding='utf8') #encoding is utf-8 otherwise throws error\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "\n",
    "print(hn[0])\n",
    "print(hn[1])\n",
    "print(hn[2])\n",
    "print(hn[3])\n",
    "print(hn[4])\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the data set [here](https://www.kaggle.com/hacker-news/hacker-news-posts), but note that it has been reduced from almost 300,000 rows to approximately 20,000 rows by removing all submissions that did not receive any comments, and then randomly sampling from the remaining submissions. Below are descriptions of the columns:\n",
    "\n",
    "|Columns| |Description|\n",
    "|-------| |-----------|\n",
    "|**id**|| The unique identifier from Hacker News for the post|\n",
    "|**title**|| The title of the post|\n",
    "|**url**|| The URL that the posts links to, if the post has a URL|\n",
    "|**num_points**|| The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes|\n",
    "|**num_comments**|| The number of comments that were made on the post|\n",
    "|**author**|| The username of the person who submitted the post|\n",
    "|**created_at**||The date and time at which the post was submitted|\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Split Data\n",
    "\n",
    "We will split the header row and keep the data in *hn*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n",
      "['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(headers)\n",
    "print('\\n')\n",
    "print(hn[0])\n",
    "print(hn[1])\n",
    "print(hn[2])\n",
    "print(hn[3])\n",
    "print(hn[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Post Categories\n",
    "\n",
    "We will create three empty lists for ask posts, show posts and other posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ask posts: 9139\n",
      "Number of show posts: 10158\n",
      "Number of other posts: 273822\n",
      "Total number of posts in data set: 293119\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print('Number of ask posts: ' + str(len(ask_posts)))\n",
    "print('Number of show posts: ' + str(len(show_posts)))\n",
    "print('Number of other posts: ' + str(len(other_posts)))\n",
    "\n",
    "print('Total number of posts in data set: ' + str(len(hn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are indeed 293119 posts in total in our dataset. There are 9k+ ask posts and 10k+ show posts and the remaining are classified as other posts.\n",
    "\n",
    "Let's check first three rows of each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']\n",
      "['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17']\n",
      "['12577908', 'Ask HN: How a DNS problem can be limited to a geographic region?', '', '1', '0', 'kuon', '9/25/2016 22:57']\n",
      "\n",
      "\n",
      "['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36']\n",
      "['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01']\n",
      "['12578098', 'Show HN: WebGL visualization of DNA sequences', 'http://grondilu.github.io/dna.html', '1', '0', 'grondilu', '9/25/2016 23:44']\n",
      "\n",
      "\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n"
     ]
    }
   ],
   "source": [
    "print(ask_posts[0])\n",
    "print(ask_posts[1])\n",
    "print(ask_posts[2])\n",
    "print('\\n')\n",
    "print(show_posts[0])\n",
    "print(show_posts[1])\n",
    "print(show_posts[2])\n",
    "print('\\n')\n",
    "print(other_posts[0])\n",
    "print(other_posts[1])\n",
    "print(other_posts[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute  Comment Averages\n",
    "Next, let's determine if ask posts or show posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ask comments: 10.393478498741656\n",
      "Average show comments: 4.886099625910612\n",
      "Average other comments: 6.4572678601427205\n"
     ]
    }
   ],
   "source": [
    "# ask comments\n",
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    total_ask_comments += int(row[4]) # index 4 for is number of comments column\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print('Average ask comments: {}'.format(avg_ask_comments))\n",
    "\n",
    "# show comments\n",
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    total_show_comments += int(row[4])\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print('Average show comments: {}'.format(avg_show_comments))\n",
    "\n",
    "# other comments \n",
    "total_other_comments = 0\n",
    "\n",
    "for row in other_posts:\n",
    "    total_other_comments += int(row[4])\n",
    "    \n",
    "avg_other_comments = total_other_comments / len(other_posts)\n",
    "print('Average other comments: {}'.format(avg_other_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen from the statistics, ask comments are twice as much as show comments on average. It is natural since ask posts are more likely to receive answers compared to show comments.\n",
    "\n",
    "Since **ask posts** are more likely to receive comments, we'll focus our remaining analysis just on these posts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Points Averages\n",
    "\n",
    "As a side analysis we have mentioned that we would analyze points on Ask HN and Show HN as well. Let's check which category gets the most points on average.\n",
    "\n",
    "*Points = Upvotes - Downvotes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ask points: 11.31174089068826\n",
      "Average show points: 14.843571569206537\n",
      "Average other points: 15.156010108756783\n"
     ]
    }
   ],
   "source": [
    "# ask points\n",
    "total_ask_points = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    total_ask_points += int(row[3]) # index 3 for number of points column\n",
    "    \n",
    "avg_ask_points = total_ask_points / len(ask_posts)\n",
    "print('Average ask points: {}'.format(avg_ask_points))\n",
    "\n",
    "# show points\n",
    "total_show_points = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    total_show_points += int(row[3])\n",
    "    \n",
    "avg_show_points = total_show_points / len(show_posts)\n",
    "print('Average show points: {}'.format(avg_show_points))\n",
    "\n",
    "# other points\n",
    "total_other_points = 0\n",
    "\n",
    "for row in other_posts:\n",
    "    total_other_points += int(row[3])\n",
    "    \n",
    "avg_other_points = total_other_points / len(other_posts)\n",
    "print('Average other points: {}'.format(avg_other_points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen from the statistics, Show HN posts are getting more points than Ask HN posts. This is also expected since people who see the posts tend to upvote or downvote a show post rather than commenting on it. Remember the goal of this project is to see the prime hour to get the most comments or our posts.\n",
    "\n",
    "## Frequency Table For Hours\n",
    "Next, we'll determine if ask posts created at a certain *time* are more likely to attract comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'02': 269, '01': 282, '22': 383, '21': 518, '19': 552, '17': 587, '15': 646, '14': 513, '13': 444, '11': 312, '10': 282, '09': 222, '07': 226, '03': 271, '23': 343, '20': 510, '16': 579, '08': 257, '00': 301, '18': 614, '12': 342, '04': 243, '06': 234, '05': 209}\n",
      "\n",
      "\n",
      "{'02': 2996, '01': 2089, '22': 3372, '21': 4500, '19': 3954, '17': 5547, '15': 18525, '14': 4972, '13': 7245, '11': 2797, '10': 3013, '09': 1477, '07': 1585, '03': 2154, '23': 2297, '20': 4462, '16': 4466, '08': 2362, '00': 2277, '18': 4877, '12': 4234, '04': 2360, '06': 1587, '05': 1838}\n",
      "\n",
      "\n",
      "{'02': 2944, '01': 2662, '22': 3601, '21': 5042, '19': 4782, '17': 7155, '15': 13978, '14': 5390, '13': 7962, '11': 2856, '10': 3789, '09': 1763, '07': 2040, '03': 2539, '23': 2616, '20': 4491, '16': 5970, '08': 2744, '00': 2835, '18': 6850, '12': 4643, '04': 2650, '06': 2030, '05': 2046}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    created_at = row[6] # index 6 for created_at column\n",
    "    num_of_comments = int(row[4]) \n",
    "    num_of_points = int(row[3])\n",
    "    result_list.append([created_at, num_of_comments, num_of_points])\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "points_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    dt_object = dt.datetime.strptime(row[0], '%m/%d/%Y %H:%M')\n",
    "    hour = dt_object.strftime('%H')\n",
    "    comments = int(row[1])\n",
    "    points = int(row[2])\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comments\n",
    "        points_by_hour[hour] = points\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comments\n",
    "        points_by_hour[hour] += points\n",
    "        \n",
    "print(counts_by_hour)\n",
    "print('\\n')\n",
    "print(comments_by_hour)\n",
    "print('\\n')\n",
    "print(points_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **counts_by_hour**: contains the number of ask posts created during each hour of the day.\n",
    "- **comments_by_hour**: contains the corresponding number of comments ask posts created at each hour received\n",
    "- **points_by_hour**: contains the corresponding number of points ask posts created at each hour received\n",
    "\n",
    "\n",
    "### Compute Averages for Comments and Points Based on Hours\n",
    "Next, we'll use these three dictionaries to calculate the *average* number of comments for posts created during each hour of the day.\n",
    "\n",
    "We'll do that by dividing total amount of comments for each hour by the total amount of posts(counts) for that hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['02', 11.137546468401487], ['01', 7.407801418439717], ['22', 8.804177545691905], ['21', 8.687258687258687], ['19', 7.163043478260869], ['17', 9.449744463373083], ['15', 28.676470588235293], ['14', 9.692007797270955], ['13', 16.31756756756757], ['11', 8.96474358974359], ['10', 10.684397163120567], ['09', 6.653153153153153], ['07', 7.013274336283186], ['03', 7.948339483394834], ['23', 6.696793002915452], ['20', 8.749019607843136], ['16', 7.713298791018998], ['08', 9.190661478599221], ['00', 7.5647840531561465], ['18', 7.94299674267101], ['12', 12.380116959064328], ['04', 9.7119341563786], ['06', 6.782051282051282], ['05', 8.794258373205741]]\n",
      "\n",
      "\n",
      "[['02', 10.944237918215613], ['01', 9.439716312056738], ['22', 9.402088772845953], ['21', 9.733590733590734], ['19', 8.66304347826087], ['17', 12.189097103918229], ['15', 21.637770897832816], ['14', 10.50682261208577], ['13', 17.93243243243243], ['11', 9.153846153846153], ['10', 13.436170212765957], ['09', 7.941441441441442], ['07', 9.026548672566372], ['03', 9.3690036900369], ['23', 7.626822157434402], ['20', 8.805882352941177], ['16', 10.310880829015543], ['08', 10.67704280155642], ['00', 9.418604651162791], ['18', 11.156351791530945], ['12', 13.576023391812866], ['04', 10.905349794238683], ['06', 8.675213675213675], ['05', 9.789473684210526]]\n"
     ]
    }
   ],
   "source": [
    "avg_comments_by_hour = []\n",
    "avg_points_by_hour = []\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "        avg_comments_by_hour.append([hour, (comments_by_hour[hour] / counts_by_hour[hour])])\n",
    "        avg_points_by_hour.append([hour, (points_by_hour[hour] / counts_by_hour[hour])])\n",
    "\n",
    "print(avg_comments_by_hour)\n",
    "print('\\n')\n",
    "print(avg_points_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swap Columns and Print Top 5 Averages\n",
    "Although we now have the results we need, this format makes it hard to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.137546468401487, '02'], [7.407801418439717, '01'], [8.804177545691905, '22'], [8.687258687258687, '21'], [7.163043478260869, '19'], [9.449744463373083, '17'], [28.676470588235293, '15'], [9.692007797270955, '14'], [16.31756756756757, '13'], [8.96474358974359, '11'], [10.684397163120567, '10'], [6.653153153153153, '09'], [7.013274336283186, '07'], [7.948339483394834, '03'], [6.696793002915452, '23'], [8.749019607843136, '20'], [7.713298791018998, '16'], [9.190661478599221, '08'], [7.5647840531561465, '00'], [7.94299674267101, '18'], [12.380116959064328, '12'], [9.7119341563786, '04'], [6.782051282051282, '06'], [8.794258373205741, '05']]\n",
      "\n",
      "\n",
      "[[10.944237918215613, '02'], [9.439716312056738, '01'], [9.402088772845953, '22'], [9.733590733590734, '21'], [8.66304347826087, '19'], [12.189097103918229, '17'], [21.637770897832816, '15'], [10.50682261208577, '14'], [17.93243243243243, '13'], [9.153846153846153, '11'], [13.436170212765957, '10'], [7.941441441441442, '09'], [9.026548672566372, '07'], [9.3690036900369, '03'], [7.626822157434402, '23'], [8.805882352941177, '20'], [10.310880829015543, '16'], [10.67704280155642, '08'], [9.418604651162791, '00'], [11.156351791530945, '18'], [13.576023391812866, '12'], [10.905349794238683, '04'], [8.675213675213675, '06'], [9.789473684210526, '05']]\n",
      "\n",
      "\n",
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 28.68 average comments per post.\n",
      "13:00: 16.32 average comments per post.\n",
      "12:00: 12.38 average comments per post.\n",
      "02:00: 11.14 average comments per post.\n",
      "10:00: 10.68 average comments per post.\n",
      "\n",
      "\n",
      "Top 5 Hours for Ask Posts Points\n",
      "15:00: 21.64 average points per post.\n",
      "13:00: 17.93 average points per post.\n",
      "12:00: 13.58 average points per post.\n",
      "10:00: 13.44 average points per post.\n",
      "17:00: 12.19 average points per post.\n"
     ]
    }
   ],
   "source": [
    "swap_avg_comments_by_hour = []\n",
    "swap_avg_points_by_hour = []\n",
    "\n",
    "# swap columns \n",
    "for row in avg_comments_by_hour:\n",
    "    swap_avg_comments_by_hour.append([row[1], row[0]])\n",
    "for row in avg_points_by_hour:\n",
    "    swap_avg_points_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "print(swap_avg_comments_by_hour)\n",
    "print('\\n')\n",
    "sorted_swap_comments = sorted(swap_avg_comments_by_hour, reverse=True)\n",
    "print(swap_avg_points_by_hour)\n",
    "print('\\n')\n",
    "sorted_swap_points = sorted(swap_avg_points_by_hour, reverse=True)\n",
    "\n",
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "\n",
    "# print top hour for comments\n",
    "for row in sorted_swap_comments[:5]:\n",
    "    hour_dt = dt.datetime.strptime(row[1], '%H')\n",
    "    hour = hour_dt.strftime('%H:%M')\n",
    "    string = '{}: {:.2f} average comments per post.'.format(hour, row[0])\n",
    "    print(string)\n",
    "\n",
    "print('\\n')\n",
    "print('Top 5 Hours for Ask Posts Points')\n",
    "\n",
    "# print top hour for points\n",
    "for row in sorted_swap_points[:5]:\n",
    "    hour_dt = dt.datetime.strptime(row[1], '%H')\n",
    "    hour = hour_dt.strftime('%H:%M')\n",
    "    string = '{}: {:.2f} average points per post.'.format(hour, row[0])\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can clearly see that top 5 hours to post an ask post on Hacker News site in order to get the maximum amount of comments. The top hour is **15:00** but it would be good to keep in mind that the time zone is *Eastern Time in the US* for this data set.\n",
    "\n",
    "#### Convert to GMT+3 Time Zone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP HOURS FOR COMMENTS AND POINTS FOR GMT+3 TIMEZONE \n",
      "\n",
      "23:00: 28.68 average comments per post.\n",
      "21:00: 16.32 average comments per post.\n",
      "20:00: 12.38 average comments per post.\n",
      "10:00: 11.14 average comments per post.\n",
      "18:00: 10.68 average comments per post.\n",
      "\n",
      "\n",
      "Top 5 Hours for Ask Posts Points\n",
      "23:00: 21.64 average points per post.\n",
      "21:00: 17.93 average points per post.\n",
      "20:00: 13.58 average points per post.\n",
      "18:00: 13.44 average points per post.\n",
      "01:00: 12.19 average points per post.\n"
     ]
    }
   ],
   "source": [
    "# print top hour for comments\n",
    "print('TOP HOURS FOR COMMENTS AND POINTS FOR GMT+3 TIMEZONE \\n')\n",
    "for row in sorted_swap_comments[:5]:\n",
    "    hour_dt = dt.datetime.strptime(row[1], '%H')\n",
    "    hour_dt += dt.timedelta(hours=8)\n",
    "    hour = hour_dt.strftime('%H:%M')\n",
    "    string = '{}: {:.2f} average comments per post.'.format(hour, row[0])\n",
    "    print(string)\n",
    "\n",
    "print('\\n')\n",
    "print('Top 5 Hours for Ask Posts Points')\n",
    "\n",
    "# print top hour for points\n",
    "for row in sorted_swap_points[:5]:\n",
    "    hour_dt = dt.datetime.strptime(row[1], '%H')\n",
    "    hour_dt += dt.timedelta(hours=8)\n",
    "    hour = hour_dt.strftime('%H:%M')\n",
    "    string = '{}: {:.2f} average points per post.'.format(hour, row[0])\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between Eastern Time in the US and GMT+3 time zone there is 8 hours of difference(I currently reside in Turkey so this time zone should be considered.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goals were to find whether Ask HN posts or Show HN posts attract more attention and also to see the prime hour in order to get most comments on our post.\n",
    "\n",
    "We have found out that Ask HN posts have higher average of comments than Show HN posts so we chose to make our analysis based on Ask HN posts.\n",
    "\n",
    "As we can see from the averages above, if we'd like to attract the most amount of comments for our **Ask HN** post the best option would be to post it on **23:00**. Likewise the most amount of points an ask post attracts based on hour is again 23:00. Thus we can say that we would hit two birds with one stone."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
